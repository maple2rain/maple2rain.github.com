title: 数据挖掘重点
date: 2017-06-05 19:51:14
updated: 2017-06-08 22:23:07
categories:
- School
---
# 考点

- 什么是噪声数据
- 为什么会有噪声数据
- 如何找到噪声数据
- 分类聚类的区别、异同点(结合实例)
- 数据预处理：平滑、归一、中值
- 贝叶斯方法、朴素贝叶斯算法
- 决策树
- K-means代码、流程图
- Aprior、FP-growth生成图
- 关联分析目的
- 2.3，2.4，3.3，4.2

# 噪声数据

## 什么是噪声数据

离群点是在数据集中偏离大部分数据的数据，使人怀疑这些数据的偏离并非由随机因素产生，而是产生于完全不同的机制。
离群点是与数据集中其余部分不服从相同统计模型的数据。
离群点是足够地不同于数据集中其余部分的数据。
离群点是远离数据集中其余部分的数据。

## 为什么会有噪声数据

- 测量、输入错误或系统运行错误所致
- 数据内在特性所决定
- 客体的异常行为所致
- 数据收集工具的问题
- 数据输入时人为或计算机错误
- 数据传输中产生错误

## 如何找到噪声数据

### 从类标号利用的程度分类
- 无监督的离群点检测方法
    在实际情况下，没有提供类标号
- 有监督的离群点检测方法
    要求存在离群点类和正常类的训练集
- 半监督的离群点检测方法
    训练数据包含被标记的正常数据，但是没有关于离群点对象的信息 

### 从主要技术路线角度分类

- 基于统计的方法

    这类方法大部分是从针对不同分布的离群点检验方法发展起来的，通常用户使用分布来拟合数据集。
    假定所给定的数据集存在一个分布或概率模型(例如，正态分布或泊松分布)，然后将与模型不一致(即分布不符合)的数据标识为离群数据。
    
- 基于距离的方法

    - 第一种策略是采用给定邻域半径，依据点的邻域中包含的对象多少来判定离群点如果一个点的邻域内包含的对象少于整个数据集的一定比例则标识它为离群点，也就是将没有足够邻居的对象看成是基于距离的离群点。
    - 利用k最近邻距离的大小来判定离群
    使用k-最近邻的距离度量一个对象是否远离大部分点，一个对象的离群程度由到它的k-最近邻的距离给定 。
    这种方法对k的取值比较敏感。k太小(例如1)，则少量的邻近离群点可能导致较低的离群程度。k太大，则点数少于k的簇中所有的对象可能都成了离群点。

    
    ![](../post_img/5937b765ab64414eac00107b)
    ![](../post_img/5937b766ab64414eac001085)
    
- 基于密度的方法

    当数据集含有多种分布或数据集由不同密度子集混合而成时，数据是否离群不仅仅取决于他与周围数据的距离大小，而且与领域内的密度状况有关。
    这里使用每个对象到第k个最近邻的距离大小来度量密度。
    
    ![](../post_img/5937b765ab64414eac00107e)
    ![](../post_img/5937b766ab64414eac001082)
    ![](../post_img/5937b766ab64414eac001084)

# 分类聚类的异同点

- 分类因为使用了类标号属性，建立了模型，具有预测功能，属于有监督的学习方法，比如训练集中的每封邮件预先被标记为垃圾邮件或合法邮件，然后对未来未知的邮件进行预测
- 聚类，事先没有使用任何类标号信息，没有进行过训练，旨在发现空间实体的属性间的函数关系，属于无监督的学习方法，比如扑克牌可以采用不同的划分方式，基于不同相似度量(花色、点数或颜色)

# 数据预处理

## 平滑

![](../post_img/5937b765ab64414eac00107a)

## 规范化

![](../post_img/5937b765ab64414eac00107d)
![](../post_img/5937b766ab64414eac001083)
![](../post_img/5937b765ab64414eac00107c)
![](../post_img/5937b766ab64414eac001080)

# 决策树
![](../post_img/593803a8ab644150cc001ad2)
![](../post_img/593803a8ab644150cc001acd)
![](../post_img/593803a8ab644150cc001ad5)
![](../post_img/593803a8ab644150cc001ad9)
![](../post_img/593803a8ab644150cc001ac9)
![](../post_img/593803a8ab644150cc001ad8)
# 贝叶斯算法

## 贝叶斯定理

$$P(X,Y) = P(Y|X)P(X) = P(X|Y)P(Y)$$
从而推导出，
$$P(Y|X) = \frac{P(X|Y)}{P(X)}P(Y)$$


![](../post_img/5937b765ab64414eac001078)
![](../post_img/5937b766ab64414eac00107f)
![](../post_img/5937b766ab64414eac001081)
![](../post_img/5937b765ab64414eac001079)

## 朴素贝叶斯定理

![](../post_img/593803a8ab644150cc001acf)
![](../post_img/593803a8ab644150cc001ad6)

![](../post_img/593803a8ab644150cc001ad0)
![](../post_img/593803a8ab644150cc001ace)
![](../post_img/593803a8ab644150cc001ad1)
![](../post_img/593803a8ab644150cc001ad4)
![](../post_img/593803a8ab644150cc001ada)
![](../post_img/593803a8ab644150cc001acc)

# K-means

## 聚类算法示例

![](../post_img/593803a8ab644150cc001aca)
![](../post_img/593803a8ab644150cc001ac6)

## 距离计算示例

![](../post_img/593803a8ab644150cc001ac8)

# 关联分析

## 目的

1. 发现数据库中隐藏的关联规则
2. 发现频繁项集

## Aprior

![](../post_img/593803a8ab644150cc001ad7)
![](../post_img/593803a8ab644150cc001ad3)

## FP-growth

![](../post_img/593803a8ab644150cc001acb)
![](../post_img/593803a8ab644150cc001ac7)